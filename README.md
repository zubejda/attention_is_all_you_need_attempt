# attention_is_all_you_need_attempt
Attempt to code the transformer in the attention is all you need paper (with different hyperparameters) and trying to train on English to Czech translation.
